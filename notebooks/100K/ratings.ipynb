{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Assignment 2***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Import neccessary libraries and load the ratings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n",
      "(100836, 4)\n",
      "Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo ratings.csv\n",
    "ratings = pd.read_csv('../../data/ml-latest-small/ratings.csv')\n",
    "\n",
    "# Ver las primeras filas\n",
    "print(ratings.head())\n",
    "\n",
    "# Revisar tamaño y columnas\n",
    "print(ratings.shape)\n",
    "print(ratings.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Preproccessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios después de filtrar: 610\n",
      "Películas después de filtrar: 3650\n"
     ]
    }
   ],
   "source": [
    "# Filtrar usuarios con menos de 10 ratings\n",
    "user_counts = ratings['userId'].value_counts()\n",
    "ratings = ratings[ratings['userId'].isin(user_counts[user_counts >= 5].index)]\n",
    "\n",
    "# Filtrar películas con menos de 10 ratings\n",
    "movie_counts = ratings['movieId'].value_counts()\n",
    "ratings = ratings[ratings['movieId'].isin(movie_counts[movie_counts >= 5].index)]\n",
    "\n",
    "print(f\"Usuarios después de filtrar: {ratings['userId'].nunique()}\")\n",
    "print(f\"Películas después de filtrar: {ratings['movieId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de usuarios únicos: 610\n",
      "Número de películas únicas: 3650\n",
      "   userId  movieId  rating  timestamp  userIndex  movieIndex\n",
      "0       1        1     4.0  964982703          0           0\n",
      "1       1        3     4.0  964981247          0           1\n",
      "2       1        6     4.0  964982224          0           2\n",
      "3       1       47     5.0  964983815          0           3\n",
      "4       1       50     5.0  964982931          0           4\n"
     ]
    }
   ],
   "source": [
    "# Obtener IDs únicos\n",
    "unique_user_ids = ratings['userId'].unique()\n",
    "unique_movie_ids = ratings['movieId'].unique()\n",
    "\n",
    "print(f\"Número de usuarios únicos: {len(unique_user_ids)}\")\n",
    "print(f\"Número de películas únicas: {len(unique_movie_ids)}\")\n",
    "\n",
    "# Crear diccionarios de mapeo\n",
    "userId_to_index = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}\n",
    "movieId_to_index = {movie_id: idx for idx, movie_id in enumerate(unique_movie_ids)}\n",
    "\n",
    "# Aplicar el mapeo al DataFrame\n",
    "ratings['userIndex'] = ratings['userId'].map(userId_to_index)\n",
    "ratings['movieIndex'] = ratings['movieId'].map(movieId_to_index)\n",
    "\n",
    "# Comprobar\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating  rating_norm\n",
      "0     4.0          0.8\n",
      "1     4.0          0.8\n",
      "2     4.0          0.8\n",
      "3     5.0          1.0\n",
      "4     5.0          1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalizamos ratings a [0, 1]\n",
    "ratings['rating_norm'] = ratings['rating'] / 5.0\n",
    "print(ratings[['rating', 'rating_norm']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Split and Prepare***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 62932\n",
      "Validation size: 13515\n",
      "Test size: 13827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Primero filtramos usuarios con al menos 3 ratings\n",
    "user_counts = ratings['userId'].value_counts()\n",
    "ratings_filtered = ratings[ratings['userId'].isin(user_counts[user_counts >= 3].index)]\n",
    "\n",
    "# Luego aplicamos el split\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "for user_id, group in ratings_filtered.groupby('userId'):\n",
    "    user_train, user_temp = train_test_split(group, test_size=0.30, random_state=42)\n",
    "    user_val, user_test = train_test_split(user_temp, test_size=0.50, random_state=42)\n",
    "    \n",
    "    train_list.append(user_train)\n",
    "    val_list.append(user_val)\n",
    "    test_list.append(user_test)\n",
    "\n",
    "train_data = pd.concat(train_list).reset_index(drop=True)\n",
    "val_data = pd.concat(val_list).reset_index(drop=True)\n",
    "test_data = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Validation size: {len(val_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Dataloaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Convertir a tensores los índices de usuario, película y ratings\n",
    "train_user = torch.tensor(train_data['userIndex'].values, dtype=torch.long)\n",
    "train_movie = torch.tensor(train_data['movieIndex'].values, dtype=torch.long)\n",
    "train_rating = torch.tensor(train_data['rating_norm'].values, dtype=torch.float32)\n",
    "\n",
    "val_user = torch.tensor(val_data['userIndex'].values, dtype=torch.long)\n",
    "val_movie = torch.tensor(val_data['movieIndex'].values, dtype=torch.long)\n",
    "val_rating = torch.tensor(val_data['rating_norm'].values, dtype=torch.float32)\n",
    "\n",
    "test_user = torch.tensor(test_data['userIndex'].values, dtype=torch.long)\n",
    "test_movie = torch.tensor(test_data['movieIndex'].values, dtype=torch.long)\n",
    "test_rating = torch.tensor(test_data['rating_norm'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Dataset Personalizado***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'user': self.users[idx],\n",
    "            'movie': self.movies[idx],\n",
    "            'rating': self.ratings[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Dataloaders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_dataset = MovieLensDataset(train_user, train_movie, train_rating)\n",
    "val_dataset = MovieLensDataset(val_user, val_movie, val_rating)\n",
    "test_dataset = MovieLensDataset(test_user, test_movie, test_rating)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Simple Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralCollaborativeFiltering(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=64, dropout_rate=0.3):\n",
    "        super(NeuralCollaborativeFiltering, self).__init__()\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "        \n",
    "        # MLP con Dropout\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, user, movie):\n",
    "        user_embedded = self.user_embedding(user)\n",
    "        movie_embedded = self.movie_embedding(movie)\n",
    "        \n",
    "        x = torch.cat([user_embedded, movie_embedded], dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.output_layer(x)\n",
    "        \n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Optimizer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con Dropout creado correctamente\n"
     ]
    }
   ],
   "source": [
    "num_users = len(userId_to_index)\n",
    "num_movies = len(movieId_to_index)\n",
    "\n",
    "model = NeuralCollaborativeFiltering(num_users=num_users, num_movies=num_movies).to(device)\n",
    "print(\"Modelo con Dropout creado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Trainning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.0792, Val Loss = 0.0420\n",
      "Epoch 2: Train Loss = 0.0526, Val Loss = 0.0398\n",
      "Epoch 3: Train Loss = 0.0486, Val Loss = 0.0382\n",
      "Epoch 4: Train Loss = 0.0458, Val Loss = 0.0371\n",
      "Epoch 5: Train Loss = 0.0435, Val Loss = 0.0360\n",
      "Epoch 6: Train Loss = 0.0422, Val Loss = 0.0355\n",
      "Epoch 7: Train Loss = 0.0411, Val Loss = 0.0347\n",
      "Epoch 8: Train Loss = 0.0400, Val Loss = 0.0347\n",
      "Epoch 9: Train Loss = 0.0393, Val Loss = 0.0341\n",
      "Epoch 10: Train Loss = 0.0386, Val Loss = 0.0338\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        users = batch['user'].to(device)\n",
    "        movies = batch['movie'].to(device)\n",
    "        ratings = batch['rating'].to(device)  # ← ya es rating_norm\n",
    "\n",
    "        preds = model(users, movies)\n",
    "        loss = criterion(preds, ratings)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(ratings)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            users = batch['user'].to(device)\n",
    "            movies = batch['movie'].to(device)\n",
    "            ratings = batch['rating'].to(device)\n",
    "\n",
    "            preds = model(users, movies)\n",
    "            loss = criterion(preds, ratings)\n",
    "            val_loss += loss.item() * len(ratings)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"solo_rantings.pth\")\n",
    "print(\"Modelo guardado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Model evaluation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***RMSE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_truth = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        users = batch['user'].to(device, dtype=torch.long)\n",
    "        movies = batch['movie'].to(device, dtype=torch.long)\n",
    "        ratings = batch['rating'].to(device, dtype=torch.float)  # Asumo ratings como float\n",
    "        \n",
    "        preds = model(users, movies)\n",
    "        \n",
    "        # Desnormalización (si ratings/preds están en 0-1)\n",
    "        all_preds.extend((preds * 5).cpu().numpy())\n",
    "        all_truth.extend((ratings * 5).cpu().numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_truth = np.array(all_truth)\n",
    "\n",
    "rmse = np.sqrt(np.mean((all_preds - all_truth) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***MAE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(all_preds - all_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***R-Square***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(all_truth, all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Precision***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "k = 10\n",
    "user_preds = defaultdict(list)\n",
    "user_truth = defaultdict(list)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        users = batch['user'].to(device, dtype=torch.long)\n",
    "        movies = batch['movie'].to(device, dtype=torch.long)\n",
    "        ratings = batch['rating'].to(device, dtype=torch.float)\n",
    "        \n",
    "        preds = model(users, movies)\n",
    "        \n",
    "        # Desnormalizamos a escala 0.5 - 5\n",
    "        preds = preds * 5\n",
    "        ratings = ratings * 5\n",
    "        \n",
    "        for u, pred, true in zip(users.cpu().numpy(), preds.cpu().numpy(), ratings.cpu().numpy()):\n",
    "            user_preds[u].append(pred)\n",
    "            user_truth[u].append(true)\n",
    "\n",
    "# Calculamos Precision@K\n",
    "precisions = []\n",
    "for u in user_preds:\n",
    "    preds_u = np.array(user_preds[u])\n",
    "    truths_u = np.array(user_truth[u])\n",
    "    \n",
    "    # Ordenar por predicción descendente y coger top K\n",
    "    top_k_indices = np.argsort(-preds_u)[:k]\n",
    "    \n",
    "    # Definir relevantes: ratings reales >= 4.0\n",
    "    relevant = (truths_u >= 4.0)\n",
    "    num_relevant = np.sum(relevant[top_k_indices])\n",
    "    \n",
    "    precision_u = num_relevant / k\n",
    "    precisions.append(precision_u)\n",
    "\n",
    "precision_at_k = np.mean(precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***NDCG@K***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(relevances, k):\n",
    "    relevances = np.asarray(relevances)[:k]\n",
    "    if relevances.size == 0:\n",
    "        return 0.0\n",
    "    # DCG: (2^rel - 1) / log2(pos + 1)\n",
    "    dcg = np.sum((2 ** relevances - 1) / np.log2(np.arange(2, relevances.size + 2)))\n",
    "    \n",
    "    # Ideal DCG: orden perfecto\n",
    "    ideal_relevances = np.sort(relevances)[::-1]\n",
    "    idcg = np.sum((2 ** ideal_relevances - 1) / np.log2(np.arange(2, ideal_relevances.size + 2)))\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# Calculamos NDCG@K para cada usuario\n",
    "ndcgs = []\n",
    "for u in user_preds:\n",
    "    preds_u = np.array(user_preds[u])\n",
    "    truths_u = np.array(user_truth[u])\n",
    "    \n",
    "    # Relevancia binaria: 1 si rating real >= 4.0, 0 en caso contrario\n",
    "    relevances = (truths_u >= 4.0).astype(int)\n",
    "    \n",
    "    # Ordenar por predicción descendente y coger top-K\n",
    "    top_k_indices = np.argsort(-preds_u)[:k]\n",
    "    \n",
    "    ndcg_u = ndcg_at_k(relevances[top_k_indices], k)\n",
    "    ndcgs.append(ndcg_u)\n",
    "\n",
    "# Media total\n",
    "ndcg_at_k_value = np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Recall@10 y F1@10*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque: Cálculo de Recall@10 y F1@10\n",
    "\n",
    "k = 10\n",
    "recalls = []\n",
    "for u in user_preds:\n",
    "    preds_u = np.array(user_preds[u])\n",
    "    truths_u = np.array(user_truth[u])\n",
    "    # Obtener los índices de los top k elementos con mayor predicción\n",
    "    top_k_indices = np.argsort(-preds_u)[:k]\n",
    "    # Definir items relevantes (ej.: rating real >= 4.0)\n",
    "    relevant = (truths_u >= 4.0)\n",
    "    total_relevant = np.sum(relevant)\n",
    "    if total_relevant > 0:\n",
    "        recall_u = np.sum(relevant[top_k_indices]) / total_relevant\n",
    "        recalls.append(recall_u)\n",
    "    else:\n",
    "        recalls.append(0.0)\n",
    "recall_at_k = np.mean(recalls)\n",
    "# Calcular F1@10: media armónica de Precision@10 y Recall@10\n",
    "f1_at_k = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k) if (precision_at_k + recall_at_k) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas agregadas al CSV: ../../performance/model_evaluations.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6095/3474256020.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_metrics_df = pd.concat([all_metrics_df, current_metrics_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Bloque: Consolidación de métricas en un CSV\n",
    "\n",
    "# Se asume que ya tienes las siguientes variables calculadas:\n",
    "# rmse, mae, r2, precision_at_k, ndcg_at_k_value, recall_at_k, f1_at_k\n",
    "\n",
    "# Crear un diccionario con las métricas del modelo actual\n",
    "current_metrics = {\n",
    "    'Modelo': 'R (100K)',  # Cambia este identificador si es necesario\n",
    "    'Test RMSE': float(np.round(rmse, 4)),\n",
    "    'Test MAE': float(np.round(mae, 4)),\n",
    "    'Test R2': float(np.round(r2, 4)),\n",
    "    'Precision@10': float(np.round(precision_at_k, 4)),\n",
    "    'Recall@10': float(np.round(recall_at_k, 4)),\n",
    "    'F1@10': float(np.round(f1_at_k, 4)),\n",
    "    'NDCG@10': float(np.round(ndcg_at_k_value, 4))\n",
    "}\n",
    "\n",
    "# Convertir el diccionario a DataFrame\n",
    "current_metrics_df = pd.DataFrame([current_metrics])\n",
    "\n",
    "# Nombre del archivo CSV donde se guardarán las métricas de todos los modelos\n",
    "metrics_csv = \"../../performance/model_evaluations.csv\"\n",
    "\n",
    "# Intentar cargar el CSV existente; si no existe, se crea uno nuevo\n",
    "try:\n",
    "    all_metrics_df = pd.read_csv(metrics_csv)\n",
    "    if all_metrics_df.empty:\n",
    "        all_metrics_df = pd.DataFrame(columns=current_metrics_df.columns)\n",
    "except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "    all_metrics_df = pd.DataFrame(columns=current_metrics_df.columns)\n",
    "\n",
    "# Agregar la nueva entrada al DataFrame existente\n",
    "all_metrics_df = pd.concat([all_metrics_df, current_metrics_df], ignore_index=True)\n",
    "\n",
    "# Guardar el CSV actualizado\n",
    "all_metrics_df.to_csv(metrics_csv, index=False)\n",
    "print(\"Métricas agregadas al CSV:\", metrics_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
