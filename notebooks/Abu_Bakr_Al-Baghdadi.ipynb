{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Import Libraries***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 1: Configuración e Importación de Librerías\n",
    "\n",
    "En este bloque se importan las principales librerías que usaremos a lo largo del notebook:\n",
    "- **Numpy y Pandas:** Para manipulación de datos.\n",
    "- **Matplotlib:** Para las visualizaciones.\n",
    "- **PyTorch:** Para definir y entrenar el modelo de recomendación.\n",
    "- **Scikit-learn:** Para la división de datos y el cálculo de métricas.\n",
    "\n",
    "Además, se configura el dispositivo de cómputo, utilizando GPU si está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Bloque 1: Configuración e Importación de Librerías\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Configurar el dispositivo: usar GPU si está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 2: Carga y Preprocesamiento de Datos\n",
    "\n",
    "En este bloque se realiza la carga del archivo `ratings.dat` y se aplica el preprocesamiento:\n",
    "- Se filtran usuarios y películas con al menos 5 ratings.\n",
    "- Se convierte el timestamp a formato datetime y se extraen características temporales (año, mes y día de la semana).\n",
    "- Se normalizan los ratings dividiéndolos por 5 para que queden en el rango [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 filas:\n",
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "\n",
      "Dimensiones del dataset: (1000209, 4)\n",
      "\n",
      "Usuarios después de filtrar: 6040\n",
      "Películas después de filtrar: 3416\n",
      "\n",
      "Resumen del preprocesamiento:\n",
      "   UserID  MovieID  Rating  Rating_Norm            Datetime  Year  Month  \\\n",
      "0       1     1193       5          1.0 2000-12-31 22:12:40  2000     12   \n",
      "1       1      661       3          0.6 2000-12-31 22:35:09  2000     12   \n",
      "2       1      914       3          0.6 2000-12-31 22:32:48  2000     12   \n",
      "3       1     3408       4          0.8 2000-12-31 22:04:35  2000     12   \n",
      "4       1     2355       5          1.0 2001-01-06 23:38:11  2001      1   \n",
      "\n",
      "   DayOfWeek  \n",
      "0          6  \n",
      "1          6  \n",
      "2          6  \n",
      "3          6  \n",
      "4          5  \n"
     ]
    }
   ],
   "source": [
    "# Bloque 2: Carga y Preprocesamiento de Datos\n",
    "\n",
    "# Cargar el dataset de ratings (asegúrate de que el archivo \"ratings.dat\" esté en el directorio actual o ajusta la ruta)\n",
    "ratings = pd.read_csv(\"../data/ml-1m/ml-1m/ratings.dat\", sep=\"::\", engine=\"python\", \n",
    "                        header=None, names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
    "\n",
    "# Mostrar las primeras filas y las dimensiones del dataset\n",
    "print(\"Primeras 5 filas:\")\n",
    "print(ratings.head())\n",
    "print(\"\\nDimensiones del dataset:\", ratings.shape)\n",
    "\n",
    "# Filtrar usuarios con al menos 5 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 5].index)]\n",
    "\n",
    "# Filtrar películas con al menos 5 ratings\n",
    "movie_counts = ratings['MovieID'].value_counts()\n",
    "ratings = ratings[ratings['MovieID'].isin(movie_counts[movie_counts >= 5].index)]\n",
    "\n",
    "print(\"\\nUsuarios después de filtrar:\", ratings['UserID'].nunique())\n",
    "print(\"Películas después de filtrar:\", ratings['MovieID'].nunique())\n",
    "\n",
    "# Convertir Timestamp a datetime y extraer características temporales\n",
    "ratings['Datetime'] = pd.to_datetime(ratings['Timestamp'], unit='s')\n",
    "ratings['Year'] = ratings['Datetime'].dt.year\n",
    "ratings['Month'] = ratings['Datetime'].dt.month\n",
    "ratings['DayOfWeek'] = ratings['Datetime'].dt.dayofweek\n",
    "\n",
    "# Normalizar los ratings a [0,1]\n",
    "ratings['Rating_Norm'] = ratings['Rating'] / 5.0\n",
    "\n",
    "# Mostrar un resumen del preprocesamiento\n",
    "print(\"\\nResumen del preprocesamiento:\")\n",
    "print(ratings[['UserID', 'MovieID', 'Rating', 'Rating_Norm', 'Datetime', 'Year', 'Month', 'DayOfWeek']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 2.1: Carga y Preprocesamiento de Datos Adicionales\n",
    "\n",
    "En este bloque cargaremos y preprocesaremos los archivos `users.dat` y `movies.dat`:\n",
    "- **users.dat:** Contiene información sobre el usuario (UserID, Gender, Age, Occupation, Zip-code).  \n",
    "  Se procesarán las variables:\n",
    "  - *Gender*: se codifica como 0 para \"F\" y 1 para \"M\".\n",
    "  - *Age* y *Occupation*: se dejan como numéricas (o se pueden transformar en categorías para generar embeddings más adelante).\n",
    "  \n",
    "- **movies.dat:** Contiene la información de las películas (MovieID, Title, Genres).  \n",
    "  Se procesará la columna *Genres*:\n",
    "  - Se separan los géneros (que vienen separados por el símbolo \"|\") para obtener una lista de géneros por película.\n",
    "  - Se genera un mapeo de cada género a un índice para usarlo posteriormente en embeddings o en una codificación multi-hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios - Primeras filas:\n",
      "   UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n",
      "\n",
      "Usuarios procesados:\n",
      "   UserID  Gender  Age  Occupation Zip-code\n",
      "0       1       0    1          10    48067\n",
      "1       2       1   56          16    70072\n",
      "2       3       1   25          15    55117\n",
      "3       4       1   45           7    02460\n",
      "4       5       1   25          20    55455\n",
      "\n",
      "Películas - Primeras filas:\n",
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "\n",
      "Películas con lista de géneros:\n",
      "   MovieID                               Title                        Genres  \\\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy   \n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy   \n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance   \n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama   \n",
      "4        5  Father of the Bride Part II (1995)                        Comedy   \n",
      "\n",
      "                        Genres_list  \n",
      "0   [Animation, Children's, Comedy]  \n",
      "1  [Adventure, Children's, Fantasy]  \n",
      "2                 [Comedy, Romance]  \n",
      "3                   [Comedy, Drama]  \n",
      "4                          [Comedy]  \n",
      "\n",
      "Mapa de Géneros a Índice:\n",
      "{'Action': 0, 'Adventure': 1, 'Animation': 2, \"Children's\": 3, 'Comedy': 4, 'Crime': 5, 'Documentary': 6, 'Drama': 7, 'Fantasy': 8, 'Film-Noir': 9, 'Horror': 10, 'Musical': 11, 'Mystery': 12, 'Romance': 13, 'Sci-Fi': 14, 'Thriller': 15, 'War': 16, 'Western': 17}\n",
      "\n",
      "Películas con índices de géneros:\n",
      "   MovieID                               Title                        Genres  \\\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy   \n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy   \n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance   \n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama   \n",
      "4        5  Father of the Bride Part II (1995)                        Comedy   \n",
      "\n",
      "                        Genres_list Genres_indices  \n",
      "0   [Animation, Children's, Comedy]      [2, 3, 4]  \n",
      "1  [Adventure, Children's, Fantasy]      [1, 3, 8]  \n",
      "2                 [Comedy, Romance]        [4, 13]  \n",
      "3                   [Comedy, Drama]         [4, 7]  \n",
      "4                          [Comedy]            [4]  \n"
     ]
    }
   ],
   "source": [
    "# Bloque 2.1: Carga y Preprocesamiento de Datos Adicionales (users.dat y movies.dat)\n",
    "\n",
    "# Cargar users.dat\n",
    "users = pd.read_csv(\"../data/ml-1m/ml-1m/users.dat\", sep=\"::\", engine=\"python\", header=None, \n",
    "                    names=[\"UserID\", \"Gender\", \"Age\", \"Occupation\", \"Zip-code\"])\n",
    "print(\"Usuarios - Primeras filas:\")\n",
    "print(users.head())\n",
    "\n",
    "# Procesar users.dat\n",
    "# Codificar Gender: F -> 0, M -> 1\n",
    "users[\"Gender\"] = users[\"Gender\"].map({\"F\": 0, \"M\": 1})\n",
    "# Convertir Age y Occupation a enteros (ya vienen como enteros en este dataset)\n",
    "users[\"Age\"] = users[\"Age\"].astype(int)\n",
    "users[\"Occupation\"] = users[\"Occupation\"].astype(int)\n",
    "print(\"\\nUsuarios procesados:\")\n",
    "print(users.head())\n",
    "\n",
    "# Cargar movies.dat\n",
    "movies = pd.read_csv(\"../data/ml-1m/ml-1m/movies.dat\", sep=\"::\", engine=\"python\", header=None, \n",
    "                     names=[\"MovieID\", \"Title\", \"Genres\"], encoding=\"latin-1\")\n",
    "print(\"\\nPelículas - Primeras filas:\")\n",
    "print(movies.head())\n",
    "\n",
    "# Procesar movies.dat\n",
    "# Separar la columna 'Genres' en una lista de géneros para cada película\n",
    "movies[\"Genres_list\"] = movies[\"Genres\"].apply(lambda x: x.split(\"|\"))\n",
    "print(\"\\nPelículas con lista de géneros:\")\n",
    "print(movies.head())\n",
    "\n",
    "# Crear un mapeo de género a índice\n",
    "all_genres = set()\n",
    "for genres in movies[\"Genres_list\"]:\n",
    "    all_genres.update(genres)\n",
    "all_genres = sorted(list(all_genres))\n",
    "genre_to_index = {genre: idx for idx, genre in enumerate(all_genres)}\n",
    "print(\"\\nMapa de Géneros a Índice:\")\n",
    "print(genre_to_index)\n",
    "\n",
    "# Para cada película, convertir la lista de géneros a una lista de índices\n",
    "movies[\"Genres_indices\"] = movies[\"Genres_list\"].apply(lambda gs: [genre_to_index[g] for g in gs])\n",
    "print(\"\\nPelículas con índices de géneros:\")\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 3: Fusión de Datos\n",
    "\n",
    "En este bloque fusionamos la información de:\n",
    "- **ratings.dat:** Contiene las interacciones (UserID, MovieID, Rating, Timestamp, etc.).\n",
    "- **users.dat:** Información de los usuarios (Gender, Age, Occupation, Zip-code).\n",
    "- **movies.dat:** Información de las películas (Title, lista de géneros y sus índices).\n",
    "\n",
    "El resultado es un DataFrame en el que cada registro de rating incluye las características adicionales tanto del usuario como de la película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del DataFrame fusionado: (999611, 16)\n",
      "Primeras filas del DataFrame fusionado:\n",
      "   UserID  MovieID  Rating  Timestamp            Datetime  Year  Month  \\\n",
      "0       1     1193       5  978300760 2000-12-31 22:12:40  2000     12   \n",
      "1       1      661       3  978302109 2000-12-31 22:35:09  2000     12   \n",
      "2       1      914       3  978301968 2000-12-31 22:32:48  2000     12   \n",
      "3       1     3408       4  978300275 2000-12-31 22:04:35  2000     12   \n",
      "4       1     2355       5  978824291 2001-01-06 23:38:11  2001      1   \n",
      "\n",
      "   DayOfWeek  Rating_Norm  Gender  Age  Occupation Zip-code  \\\n",
      "0          6          1.0       0    1          10    48067   \n",
      "1          6          0.6       0    1          10    48067   \n",
      "2          6          0.6       0    1          10    48067   \n",
      "3          6          0.8       0    1          10    48067   \n",
      "4          5          1.0       0    1          10    48067   \n",
      "\n",
      "                                    Title                       Genres_list  \\\n",
      "0  One Flew Over the Cuckoo's Nest (1975)                           [Drama]   \n",
      "1        James and the Giant Peach (1996)  [Animation, Children's, Musical]   \n",
      "2                     My Fair Lady (1964)                [Musical, Romance]   \n",
      "3                  Erin Brockovich (2000)                           [Drama]   \n",
      "4                    Bug's Life, A (1998)   [Animation, Children's, Comedy]   \n",
      "\n",
      "  Genres_indices  \n",
      "0            [7]  \n",
      "1     [2, 3, 11]  \n",
      "2       [11, 13]  \n",
      "3            [7]  \n",
      "4      [2, 3, 4]  \n"
     ]
    }
   ],
   "source": [
    "# Bloque 3: Fusión de Datos\n",
    "\n",
    "# Fusionar ratings con users utilizando 'UserID'\n",
    "ratings_merged = ratings.merge(users, on=\"UserID\", how=\"left\")\n",
    "\n",
    "# Fusionar el resultado con movies utilizando 'MovieID'\n",
    "# Seleccionamos solo las columnas relevantes de movies\n",
    "ratings_merged = ratings_merged.merge(movies[['MovieID', 'Title', 'Genres_list', 'Genres_indices']], on=\"MovieID\", how=\"left\")\n",
    "\n",
    "print(\"Dimensiones del DataFrame fusionado:\", ratings_merged.shape)\n",
    "print(\"Primeras filas del DataFrame fusionado:\")\n",
    "print(ratings_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del CSV OMDb: (1438, 9)\n",
      "Primeras filas del CSV OMDb:\n",
      "   MovieID                                              Title  IMDbRating  \\\n",
      "0        1  Toy Story (1995)/The Wrestler (2008) - 99 Movi...         NaN   \n",
      "1        2                                     Jumanji (1995)         NaN   \n",
      "2        6                                   313: Heat (1995)         NaN   \n",
      "3       18                 Four Rooms (1995) VHS Movie Review         NaN   \n",
      "4       27                                Now And Then (1995)         NaN   \n",
      "\n",
      "  Plot Director Actors      Genre Runtime      Released  \n",
      "0  NaN      NaN    NaN        NaN     NaN   03 Feb 2021  \n",
      "1  NaN      NaN    NaN  Talk-Show     NaN   11 May 2022  \n",
      "2  NaN      NaN    NaN        NaN     NaN   26 Jul 2019  \n",
      "3  NaN      NaN    NaN        NaN     NaN   24 Oct 2019  \n",
      "4  NaN      NaN    NaN        NaN     NaN  30 Jun 2021   \n",
      "Dimensiones del DataFrame enriquecido: (1016868, 24)\n",
      "Primeras filas del DataFrame enriquecido:\n",
      "   UserID MovieID  Rating  Timestamp            Datetime  Year  Month  \\\n",
      "0       1    1193       5  978300760 2000-12-31 22:12:40  2000     12   \n",
      "1       1     661       3  978302109 2000-12-31 22:35:09  2000     12   \n",
      "2       1     914       3  978301968 2000-12-31 22:32:48  2000     12   \n",
      "3       1    3408       4  978300275 2000-12-31 22:04:35  2000     12   \n",
      "4       1    2355       5  978824291 2001-01-06 23:38:11  2001      1   \n",
      "\n",
      "   DayOfWeek  Rating_Norm  Gender  ...                       Genres_list  \\\n",
      "0          6          1.0       0  ...                           [Drama]   \n",
      "1          6          0.6       0  ...  [Animation, Children's, Musical]   \n",
      "2          6          0.6       0  ...                [Musical, Romance]   \n",
      "3          6          0.8       0  ...                           [Drama]   \n",
      "4          5          1.0       0  ...   [Animation, Children's, Comedy]   \n",
      "\n",
      "   Genres_indices                       Title_omdb IMDbRating  \\\n",
      "0             [7]  One Flew Over the Cuckoo's Nest        8.7   \n",
      "1      [2, 3, 11]        James and the Giant Peach        6.7   \n",
      "2        [11, 13]                     My Fair Lady        7.7   \n",
      "3             [7]                              NaN        NaN   \n",
      "4       [2, 3, 4]                              NaN        NaN   \n",
      "\n",
      "                                                Plot      Director  \\\n",
      "0  In the Fall of 1963, a Korean War veteran and ...  Milos Forman   \n",
      "1  An orphan who lives with his two cruel aunts b...  Henry Selick   \n",
      "2  In 1910s London, snobbish phonetics professor ...  George Cukor   \n",
      "3                                                NaN           NaN   \n",
      "4                                                NaN           NaN   \n",
      "\n",
      "                                              Actors  \\\n",
      "0  Jack Nicholson, Louise Fletcher, Michael Berryman   \n",
      "1      Paul Terry, Joanna Lumley, Pete Postlethwaite   \n",
      "2     Audrey Hepburn, Rex Harrison, Stanley Holloway   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                          Genre  Runtime     Released  \n",
      "0                         Drama  133 min  19 Nov 1975  \n",
      "1  Animation, Adventure, Family   79 min  12 Apr 1996  \n",
      "2        Drama, Family, Musical  170 min  25 Dec 1964  \n",
      "3                           NaN      NaN          NaN  \n",
      "4                           NaN      NaN          NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Bloque 3.1: Integración de Datos Extra de OMDb\n",
    "\n",
    "# Cargar el CSV extra de OMDb\n",
    "omdb_df = pd.read_csv(\"../scrapping/omdb_movie_data.csv\", encoding=\"utf-8\")\n",
    "print(\"Dimensiones del CSV OMDb:\", omdb_df.shape)\n",
    "print(\"Primeras filas del CSV OMDb:\")\n",
    "print(omdb_df.head())\n",
    "\n",
    "# Asegurarse de que las columnas \"MovieID\" sean del mismo tipo en ambos DataFrames\n",
    "# Convertimos a string en ambos casos\n",
    "ratings_merged[\"MovieID\"] = ratings_merged[\"MovieID\"].astype(str)\n",
    "omdb_df[\"MovieID\"] = omdb_df[\"MovieID\"].astype(str)\n",
    "\n",
    "# Fusionar ratings_merged con omdb_df usando \"MovieID\" como llave (left join)\n",
    "# Usamos el sufijo '_omdb' para las columnas del CSV extra, en caso de conflicto.\n",
    "ratings_enriched = ratings_merged.merge(omdb_df, on=\"MovieID\", how=\"left\", suffixes=(\"\", \"_omdb\"))\n",
    "\n",
    "print(\"Dimensiones del DataFrame enriquecido:\", ratings_enriched.shape)\n",
    "print(\"Primeras filas del DataFrame enriquecido:\")\n",
    "print(ratings_enriched.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en ratings_enriched: Index(['UserID', 'MovieID', 'Rating', 'Timestamp', 'Datetime', 'Year', 'Month',\n",
      "       'DayOfWeek', 'Rating_Norm', 'Gender', 'Age', 'Occupation', 'Zip-code',\n",
      "       'Title', 'Genres_list', 'Genres_indices', 'Title_omdb', 'IMDbRating',\n",
      "       'Plot', 'Director', 'Actors', 'Genre', 'Runtime', 'Released',\n",
      "       'Genres_multi_hot'],\n",
      "      dtype='object')\n",
      "Tamaño de train_df: (709091, 25)\n",
      "Tamaño de val_df: (152350, 25)\n",
      "Tamaño de test_df: (155427, 25)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Asegurarnos de que ratings_enriched tiene la columna 'Genres_multi_hot'\n",
    "if 'Genres_multi_hot' not in ratings_enriched.columns:\n",
    "    ratings_enriched['Genres_multi_hot'] = ratings_enriched['Genres_indices'].apply(create_multi_hot)\n",
    "\n",
    "print(\"Columnas en ratings_enriched:\", ratings_enriched.columns)\n",
    "\n",
    "# Dividir el DataFrame enriquecido en train, validation y test agrupando por 'UserID'\n",
    "train_list, val_list, test_list = [], [], []\n",
    "for user_id, group in ratings_enriched.groupby(\"UserID\"):\n",
    "    group = group.sort_values(\"Timestamp\")\n",
    "    train, temp = train_test_split(group, test_size=0.30, random_state=42)\n",
    "    val, test = train_test_split(temp, test_size=0.50, random_state=42)\n",
    "    train_list.append(train)\n",
    "    val_list.append(val)\n",
    "    test_list.append(test)\n",
    "\n",
    "train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "val_df = pd.concat(val_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño de train_df:\", train_df.shape)\n",
    "print(\"Tamaño de val_df:\", val_df.shape)\n",
    "print(\"Tamaño de test_df:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 4: Creación del Dataset Personalizado y DataLoaders (Actualizado)\n",
    "\n",
    "En este bloque actualizaremos la clase de Dataset para incluir las nuevas características:\n",
    "- Se generan índices numéricos para usuarios y películas.\n",
    "- Se crea una representación multi-hot para los géneros de las películas.\n",
    "- Se retorna, para cada muestra, no solo el rating y los índices, sino también:\n",
    "  - `user_features`: [Gender, Age, Occupation].\n",
    "  - `movie_features`: vector multi-hot de géneros.\n",
    "\n",
    "Finalmente, se crean los DataLoaders para entrenamiento, validación y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en train_df: Index(['UserID', 'MovieID', 'Rating', 'Timestamp', 'Datetime', 'Year', 'Month',\n",
      "       'DayOfWeek', 'Rating_Norm', 'Gender', 'Age', 'Occupation', 'Zip-code',\n",
      "       'Title', 'Genres_list', 'Genres_indices', 'Title_omdb', 'IMDbRating',\n",
      "       'Plot', 'Director', 'Actors', 'Genre', 'Runtime', 'Released',\n",
      "       'Genres_multi_hot', 'userIndex', 'movieIndex'],\n",
      "      dtype='object')\n",
      "Tamaño del dataset de entrenamiento (con OMDb): 709091\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "class MovieLensEnhancedOMDbDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # Características básicas: índices y rating normalizado\n",
    "        self.users = torch.tensor(data['userIndex'].values, dtype=torch.long)\n",
    "        self.movies = torch.tensor(data['movieIndex'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(data['Rating_Norm'].values, dtype=torch.float32)\n",
    "        \n",
    "        # Características del usuario: Gender, Age, Occupation\n",
    "        self.user_features = torch.tensor(data[['Gender', 'Age', 'Occupation']].values, dtype=torch.float32)\n",
    "        \n",
    "        # Características de la película: vector multi-hot de géneros (ya generado)\n",
    "        self.movie_features = data['Genres_multi_hot'].values  # Se procesa en __getitem__\n",
    "        \n",
    "        # Datos extra de OMDb:\n",
    "        # Convertir IMDbRating a numérico; si falla se completa con 0\n",
    "        self.imdb_rating = torch.tensor(\n",
    "            pd.to_numeric(data['IMDbRating'], errors='coerce').fillna(0).values, \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        # Extraer y convertir la duración de Runtime usando parse_runtime\n",
    "        def parse_runtime(rt):\n",
    "            if pd.isna(rt):\n",
    "                return 0.0\n",
    "            match = re.search(r'(\\d+)', str(rt))\n",
    "            if match:\n",
    "                return float(match.group(1))\n",
    "            return 0.0\n",
    "        self.runtime = torch.tensor(data['Runtime'].apply(parse_runtime).values, dtype=torch.float32)\n",
    "        \n",
    "        # Guardamos los campos textuales para procesamiento posterior (sin procesar aún)\n",
    "        self.plot = data['Plot'].values\n",
    "        self.director = data['Director'].values\n",
    "        self.actors = data['Actors'].values\n",
    "        self.omdb_genre = data['Genre'].values\n",
    "        self.released = data['Released'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convertir la lista multi-hot a tensor\n",
    "        movie_feat = torch.tensor(self.movie_features[idx], dtype=torch.float32)\n",
    "        return {\n",
    "            \"user\": self.users[idx],\n",
    "            \"movie\": self.movies[idx],\n",
    "            \"rating\": self.ratings[idx],\n",
    "            \"user_features\": self.user_features[idx],\n",
    "            \"movie_features\": movie_feat,\n",
    "            \"imdb_rating\": self.imdb_rating[idx],\n",
    "            \"runtime\": self.runtime[idx],\n",
    "            \"plot\": self.plot[idx],          # Texto (sin procesar)\n",
    "            \"director\": self.director[idx],  # Texto (sin procesar)\n",
    "            \"actors\": self.actors[idx],      # Texto (sin procesar)\n",
    "            \"omdb_genre\": self.omdb_genre[idx],  # Texto (sin procesar)\n",
    "            \"released\": self.released[idx]   # Texto (sin procesar)\n",
    "        }\n",
    "\n",
    "# Asegurarnos de que train_df, val_df y test_df tienen las columnas 'userIndex' y 'movieIndex'\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    if 'userIndex' not in df.columns:\n",
    "        df['userIndex'] = pd.factorize(df['UserID'])[0]\n",
    "    if 'movieIndex' not in df.columns:\n",
    "        df['movieIndex'] = pd.factorize(df['MovieID'])[0]\n",
    "\n",
    "print(\"Columnas en train_df:\", train_df.columns)\n",
    "\n",
    "# Crear instancias del Dataset enriquecido\n",
    "train_dataset_omdb = MovieLensEnhancedOMDbDataset(train_df)\n",
    "val_dataset_omdb   = MovieLensEnhancedOMDbDataset(val_df)\n",
    "test_dataset_omdb  = MovieLensEnhancedOMDbDataset(test_df)\n",
    "\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "def custom_collate(batch):\n",
    "    collated = {}\n",
    "    # Definimos explícitamente las claves que contienen texto\n",
    "    text_keys = [\"plot\", \"director\", \"actors\", \"omdb_genre\", \"released\"]\n",
    "    for key in batch[0]:\n",
    "        if key in text_keys:\n",
    "            collated[key] = [d[key] for d in batch]\n",
    "        else:\n",
    "            collated[key] = default_collate([d[key] for d in batch])\n",
    "    return collated\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 512\n",
    "train_loader_omdb = DataLoader(train_dataset_omdb, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=custom_collate)\n",
    "val_loader_omdb   = DataLoader(val_dataset_omdb, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=custom_collate)\n",
    "test_loader_omdb  = DataLoader(test_dataset_omdb, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=custom_collate)\n",
    "\n",
    "print(\"Tamaño del dataset de entrenamiento (con OMDb):\", len(train_dataset_omdb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 5: Definición del Modelo Mejorado (Integrando Datos Adicionales)\n",
    "\n",
    "En este bloque definimos un modelo que, además de utilizar los índices de usuario y película, incorpora:\n",
    "- **Características del usuario:** [Gender, Age, Occupation].  \n",
    "- **Características de la película:** Representación multi-hot de géneros.\n",
    "\n",
    "La arquitectura consiste en:\n",
    "1. Obtener embeddings para el ID de usuario y de película.\n",
    "2. Transformar las características adicionales mediante capas lineales.\n",
    "3. Combinar (concatenar) las representaciones y pasarlas por una red MLP para obtener la predicción final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuMFEnhancedOMDb(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, n_genres,\n",
    "                 user_embedding_dim=32, movie_embedding_dim=32,\n",
    "                 user_feature_dim=3, movie_feature_output_dim=16,\n",
    "                 extra_movie_feature_dim=2, extra_movie_hidden_dim=8,\n",
    "                 mlp_layers=[128, 64], dropout=0.3):\n",
    "        super(NeuMFEnhancedOMDb, self).__init__()\n",
    "        \n",
    "        # Embeddings\n",
    "        self.user_embedding = nn.Embedding(num_users, user_embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, movie_embedding_dim)\n",
    "        \n",
    "        # Transformación de features de usuario\n",
    "        self.user_feat_fc = nn.Sequential(\n",
    "            nn.Linear(user_feature_dim, user_embedding_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Transformación de géneros (multi-hot)\n",
    "        self.movie_feat_fc = nn.Sequential(\n",
    "            nn.Linear(n_genres, movie_feature_output_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Transformación de IMDbRating + Runtime\n",
    "        self.extra_movie_fc = nn.Sequential(\n",
    "            nn.Linear(extra_movie_feature_dim, extra_movie_hidden_dim),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Dimensiones combinadas\n",
    "        user_combined_dim = user_embedding_dim * 2\n",
    "        movie_combined_dim = movie_embedding_dim + movie_feature_output_dim + extra_movie_hidden_dim\n",
    "        fusion_input_dim = user_combined_dim + movie_combined_dim\n",
    "        \n",
    "        # Red MLP de fusión\n",
    "        self.fusion_mlp = nn.Sequential(\n",
    "            nn.Linear(fusion_input_dim, mlp_layers[0]),\n",
    "            nn.BatchNorm1d(mlp_layers[0]),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_layers[0], mlp_layers[1]),\n",
    "            nn.BatchNorm1d(mlp_layers[1]),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "        # Salida final normalizada (opcional: usar sigmoid y escalar a [1, 5])\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(mlp_layers[1], 1),\n",
    "            nn.Sigmoid()  # Salida entre 0 y 1 → luego la escalas si quieres a [1, 5]\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_id, movie_id, user_features, movie_features, extra_movie_features):\n",
    "        # Embeddings\n",
    "        user_emb = self.user_embedding(user_id)\n",
    "        movie_emb = self.movie_embedding(movie_id)\n",
    "        \n",
    "        # Procesar features\n",
    "        user_extra = self.user_feat_fc(user_features)\n",
    "        movie_basic = self.movie_feat_fc(movie_features)\n",
    "        \n",
    "        # Normalizar explícitamente IMDbRating y Runtime a [0, 1]\n",
    "        x_extra = extra_movie_features.clone()\n",
    "        x_extra[:, 0] = x_extra[:, 0] / 10.0        # IMDbRating\n",
    "        x_extra[:, 1] = x_extra[:, 1] / 180.0       # Runtime (suponiendo máx 180 min aprox)\n",
    "        extra_movie = self.extra_movie_fc(x_extra)\n",
    "        \n",
    "        # Combinar usuario y película\n",
    "        user_vec = torch.cat([user_emb, user_extra], dim=1)\n",
    "        movie_vec = torch.cat([movie_emb, movie_basic, extra_movie], dim=1)\n",
    "        x = torch.cat([user_vec, movie_vec], dim=1)\n",
    "        \n",
    "        # Pasar por MLP\n",
    "        x = self.fusion_mlp(x)\n",
    "        out = self.output(x) * 4 + 1  # Reconvertimos a [1, 5]\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloque 6: Entrenamiento del Modelo Mejorado\n",
    "\n",
    "En este bloque entrenaremos el modelo mejorado (NeuMFEnhanced) usando el dataset enriquecido (train_loader_enh, val_loader_enh y test_loader_enh).  \n",
    "Se usará una función de pérdida MSE, el optimizador Adam y un scheduler para reducir la tasa de aprendizaje en caso de que la pérdida de validación no mejore.  \n",
    "Implementaremos early stopping basado en la pérdida de validación para evitar sobreentrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuMFEnhancedOMDb(\n",
      "  (user_embedding): Embedding(6040, 32)\n",
      "  (movie_embedding): Embedding(3416, 32)\n",
      "  (user_feat_fc): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=32, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "  )\n",
      "  (movie_feat_fc): Sequential(\n",
      "    (0): Linear(in_features=18, out_features=16, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "  )\n",
      "  (extra_movie_fc): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=8, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "  )\n",
      "  (fusion_mlp): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GELU(approximate='none')\n",
      "    (7): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Bloque 5: Definición del Modelo Mejorado con Datos Extra (OMDb)\n",
    "\n",
    "# Dimensiones de entrada\n",
    "num_users = train_df['userIndex'].max() + 1\n",
    "num_movies = train_df['movieIndex'].max() + 1\n",
    "n_genres = len(genre_to_index)  # número de géneros (dimensión del vector multi-hot)\n",
    "\n",
    "# Instancia del modelo\n",
    "model_enhanced_omdb = NeuMFEnhancedOMDb(\n",
    "    num_users=num_users,\n",
    "    num_movies=num_movies,\n",
    "    n_genres=n_genres,\n",
    "    user_embedding_dim=32,\n",
    "    movie_embedding_dim=32,\n",
    "    user_feature_dim=3,\n",
    "    movie_feature_output_dim=16,\n",
    "    extra_movie_feature_dim=2,    # IMDbRating + Runtime\n",
    "    extra_movie_hidden_dim=8,\n",
    "    mlp_layers=[128, 64],\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(model_enhanced_omdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 0.3114 - Val RMSE: 0.3646 - MAE: 0.2881 - R²: -1.6623\n",
      "Epoch 2/10 - Train Loss: 0.1335 - Val RMSE: 0.3602 - MAE: 0.2826 - R²: -1.5995\n",
      "Epoch 3/10 - Train Loss: 0.1315 - Val RMSE: 0.3596 - MAE: 0.2817 - R²: -1.5897\n",
      "Epoch 4/10 - Train Loss: 0.1310 - Val RMSE: 0.3594 - MAE: 0.2815 - R²: -1.5868\n",
      "Epoch 5/10 - Train Loss: 0.1308 - Val RMSE: 0.3593 - MAE: 0.2814 - R²: -1.5858\n",
      "Epoch 6/10 - Train Loss: 0.1308 - Val RMSE: 0.3593 - MAE: 0.2814 - R²: -1.5860\n",
      "Epoch 7/10 - Train Loss: 0.1307 - Val RMSE: 0.3593 - MAE: 0.2814 - R²: -1.5861\n",
      "Epoch 8/10 - Train Loss: 0.1307 - Val RMSE: 0.3593 - MAE: 0.2813 - R²: -1.5854\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m     63\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model_enhanced_omdb\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m \u001b[43mtrain_enhanced_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_enhanced_omdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_omdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_omdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Evaluación final en test\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_model_on_test\u001b[39m(model, test_loader):\n",
      "Cell \u001b[0;32mIn[52], line 24\u001b[0m, in \u001b[0;36mtrain_enhanced_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m extra_movie_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m     19\u001b[0m     batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimdb_rating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     20\u001b[0m     batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_movie_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, rating)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/work/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/work/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[49], line 76\u001b[0m, in \u001b[0;36mNeuMFEnhancedOMDb.forward\u001b[0;34m(self, user_id, movie_id, user_features, movie_features, extra_movie_features)\u001b[0m\n\u001b[1;32m     74\u001b[0m user_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([user_emb, user_extra], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     75\u001b[0m movie_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([movie_emb, movie_basic, extra_movie], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_vec\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Pasar por MLP\u001b[39;00m\n\u001b[1;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfusion_mlp(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_enhanced_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            user = batch['user'].to(device)\n",
    "            movie = batch['movie'].to(device)\n",
    "            rating = batch['rating'].to(device)\n",
    "            user_features = batch['user_features'].to(device)\n",
    "            movie_features = batch['movie_features'].to(device)\n",
    "            \n",
    "            # Extra features: IMDbRating y Runtime (dim 2)\n",
    "            extra_movie_features = torch.stack([\n",
    "                batch['imdb_rating'].to(device),\n",
    "                batch['runtime'].to(device)\n",
    "            ], dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(user, movie, user_features, movie_features, extra_movie_features)\n",
    "            loss = criterion(output, rating)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * rating.size(0)\n",
    "        \n",
    "        avg_train_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Evaluación en validación\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                user = batch['user'].to(device)\n",
    "                movie = batch['movie'].to(device)\n",
    "                rating = batch['rating'].to(device)\n",
    "                user_features = batch['user_features'].to(device)\n",
    "                movie_features = batch['movie_features'].to(device)\n",
    "                extra_movie_features = torch.stack([\n",
    "                    batch['imdb_rating'].to(device),\n",
    "                    batch['runtime'].to(device)\n",
    "                ], dim=1)\n",
    "\n",
    "                output = model(user, movie, user_features, movie_features, extra_movie_features)\n",
    "                val_preds.append(output.cpu().numpy())\n",
    "                val_targets.append(rating.cpu().numpy())\n",
    "\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_targets = np.concatenate(val_targets)\n",
    "        val_rmse = np.sqrt(mean_squared_error(val_targets, val_preds))\n",
    "        val_mae = mean_absolute_error(val_targets, val_preds)\n",
    "        val_r2 = r2_score(val_targets, val_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f} - \"\n",
    "              f\"Val RMSE: {val_rmse:.4f} - MAE: {val_mae:.4f} - R²: {val_r2:.4f}\")\n",
    "\n",
    "# Entrenamiento\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_enhanced_omdb.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "train_enhanced_model(model_enhanced_omdb, train_loader_omdb, val_loader_omdb, optimizer, criterion, num_epochs=10)\n",
    "\n",
    "# Evaluación final en test\n",
    "def evaluate_model_on_test(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            user = batch['user'].to(device)\n",
    "            movie = batch['movie'].to(device)\n",
    "            rating = batch['rating'].to(device)\n",
    "            user_features = batch['user_features'].to(device)\n",
    "            movie_features = batch['movie_features'].to(device)\n",
    "            extra_movie_features = torch.stack([\n",
    "                batch['imdb_rating'].to(device),\n",
    "                batch['runtime'].to(device)\n",
    "            ], dim=1)\n",
    "\n",
    "            output = model(user, movie, user_features, movie_features, extra_movie_features)\n",
    "            all_preds.append(output.cpu().numpy())\n",
    "            all_targets.append(rating.cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(all_preds)\n",
    "    targets = np.concatenate(all_targets)\n",
    "    rmse = np.sqrt(mean_squared_error(targets, preds))\n",
    "    mae = mean_absolute_error(targets, preds)\n",
    "    r2 = r2_score(targets, preds)\n",
    "\n",
    "    print(\"\\nEvaluación del Modelo Mejorado (OMDb) en el conjunto de test:\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# Ejecutar evaluación\n",
    "evaluate_model_on_test(model_enhanced_omdb, test_loader_omdb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
