{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Assignment 2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Import neccessary libraries and load the ratings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "(1000209, 4)\n",
      "Index(['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype='object')\n",
      "Usuarios despu√©s de filtrar: 6040\n",
      "Pel√≠culas despu√©s de filtrar: 3416\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo ratings.dat especificando el separador '::'\n",
    "ratings = pd.read_csv(\"../../data/ml-1m/ratings.dat\", sep=\"::\", engine=\"python\", header=None,\n",
    "                      names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
    "\n",
    "# Mostrar las primeras filas para verificar la carga\n",
    "print(ratings.head())\n",
    "print(ratings.shape)\n",
    "print(ratings.columns)\n",
    "\n",
    "# Filtro: usuarios con al menos 5 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings = ratings[ratings['UserID'].isin(user_counts[user_counts >= 5].index)]\n",
    "\n",
    "# Filtro: pel√≠culas con al menos 5 ratings\n",
    "movie_counts = ratings['MovieID'].value_counts()\n",
    "ratings = ratings[ratings['MovieID'].isin(movie_counts[movie_counts >= 5].index)]\n",
    "\n",
    "print(f\"Usuarios despu√©s de filtrar: {ratings['UserID'].nunique()}\")\n",
    "print(f\"Pel√≠culas despu√©s de filtrar: {ratings['MovieID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating  rating_norm  rating_std\n",
      "0       5          1.0    1.269615\n",
      "1       3          0.6   -0.521065\n",
      "2       3          0.6   -0.521065\n",
      "3       4          0.8    0.374275\n",
      "4       5          1.0    1.269615\n",
      "Media original: 3.5820 | Desviaci√≥n: 1.1169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Mapeo de IDs con LabelEncoder (m√°s ordenado y reutilizable)\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "ratings['userIndex'] = user_encoder.fit_transform(ratings['UserID'])\n",
    "ratings['movieIndex'] = movie_encoder.fit_transform(ratings['MovieID'])\n",
    "\n",
    "# Normalizaci√≥n a [0, 1]\n",
    "ratings['rating_norm'] = ratings['Rating'] / 5.0\n",
    "\n",
    "# Estandarizaci√≥n (media 0, desviaci√≥n 1)\n",
    "mean_rating = ratings['Rating'].mean()\n",
    "std_rating = ratings['Rating'].std()\n",
    "ratings['rating_std'] = (ratings['Rating'] - mean_rating) / std_rating\n",
    "\n",
    "# Mostrar resumen\n",
    "print(ratings[['Rating', 'rating_norm', 'rating_std']].head())\n",
    "print(f\"Media original: {mean_rating:.4f} | Desviaci√≥n: {std_rating:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Timestamp            datetime  year  month  dayofweek\n",
      "0  978300760 2000-12-31 22:12:40  2000     12          6\n",
      "1  978302109 2000-12-31 22:35:09  2000     12          6\n",
      "2  978301968 2000-12-31 22:32:48  2000     12          6\n",
      "3  978300275 2000-12-31 22:04:35  2000     12          6\n",
      "4  978824291 2001-01-06 23:38:11  2001      1          5\n"
     ]
    }
   ],
   "source": [
    "# Convertir timestamp a datetime\n",
    "ratings['datetime'] = pd.to_datetime(ratings['Timestamp'], unit='s')\n",
    "\n",
    "# Extraer a√±o, mes y d√≠a de la semana\n",
    "ratings['year'] = ratings['datetime'].dt.year\n",
    "ratings['month'] = ratings['datetime'].dt.month\n",
    "ratings['dayofweek'] = ratings['datetime'].dt.dayofweek  # 0=Lunes, 6=Domingo\n",
    "\n",
    "# Mostrar resumen\n",
    "print(ratings[['Timestamp', 'datetime', 'year', 'month', 'dayofweek']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Import neccessary libraries and load the movies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "(3883, 3)\n",
      "Index(['MovieID', 'Title', 'Genres'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo movies.dat con codificaci√≥n ISO-8859-1 y separador '::'\n",
    "movies = pd.read_csv(\"../../data/ml-1m/movies.dat\", sep=\"::\", engine=\"python\", header=None,\n",
    "                     names=[\"MovieID\", \"Title\", \"Genres\"], encoding=\"latin1\")\n",
    "\n",
    "# Mostrar las primeras filas para verificar la carga\n",
    "print(movies.head())\n",
    "print(movies.shape)\n",
    "print(movies.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Unir ratings y Movies***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID                                   Title  \\\n",
      "0     1193  One Flew Over the Cuckoo's Nest (1975)   \n",
      "1      661        James and the Giant Peach (1996)   \n",
      "2      914                     My Fair Lady (1964)   \n",
      "3     3408                  Erin Brockovich (2000)   \n",
      "4     2355                    Bug's Life, A (1998)   \n",
      "\n",
      "                         Genres  \n",
      "0                         Drama  \n",
      "1  Animation|Children's|Musical  \n",
      "2               Musical|Romance  \n",
      "3                         Drama  \n",
      "4   Animation|Children's|Comedy  \n"
     ]
    }
   ],
   "source": [
    "# Unir ratings con movies usando MovieID\n",
    "ratings = ratings.merge(movies, on=\"MovieID\", how=\"inner\")\n",
    "\n",
    "# Mostrar algunas columnas nuevas para comprobar\n",
    "print(ratings[['MovieID', 'Title', 'Genres']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***one hot encoding para los generos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
      "                                    Title  Action  Adventure  Animation  \\\n",
      "0  One Flew Over the Cuckoo's Nest (1975)       0          0          0   \n",
      "1        James and the Giant Peach (1996)       0          0          1   \n",
      "2                     My Fair Lady (1964)       0          0          0   \n",
      "\n",
      "   Children's  Comedy  Crime  Documentary  Drama  Fantasy  Film-Noir  Horror  \\\n",
      "0           0       0      0            0      1        0          0       0   \n",
      "1           1       0      0            0      0        0          0       0   \n",
      "2           0       0      0            0      0        0          0       0   \n",
      "\n",
      "   Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0        0       0         0    0        0  \n",
      "1        1        0        0       0         0    0        0  \n",
      "2        1        0        1       0         0    0        0  \n"
     ]
    }
   ],
   "source": [
    "# Separar los g√©neros por '|' y obtener one-hot encoding\n",
    "genres_onehot = ratings['Genres'].str.get_dummies(sep='|')\n",
    "\n",
    "# A√±adir los g√©neros al dataframe de ratings\n",
    "ratings = pd.concat([ratings, genres_onehot], axis=1)\n",
    "\n",
    "# Mostrar las columnas de g√©nero\n",
    "print(genres_onehot.columns.tolist())\n",
    "print(ratings[['Title'] + genres_onehot.columns.tolist()].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Extraer los generos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([999611, 18])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "genre_columns = genres_onehot.columns.tolist()\n",
    "\n",
    "# Extraer vectores de g√©nero para cada entrada\n",
    "genre_vectors = torch.tensor(ratings[genre_columns].values, dtype=torch.float32)\n",
    "\n",
    "# Mostrar ejemplo\n",
    "print(genre_vectors.shape)\n",
    "print(genre_vectors[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***dataset personalizado***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, users, movies, genres, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.genres = genres\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'user': self.users[idx],\n",
    "            'movie': self.movies[idx],\n",
    "            'genre': self.genres[idx],\n",
    "            'rating': self.ratings[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Elegimos columna de rating\n",
    "rating_col = 'rating_norm'  # o 'rating_std'\n",
    "\n",
    "# Filtrar usuarios con al menos 3 ratings\n",
    "user_counts = ratings['UserID'].value_counts()\n",
    "ratings_filtered = ratings[ratings['UserID'].isin(user_counts[user_counts >= 3].index)]\n",
    "\n",
    "# Nuevo split\n",
    "train_list, val_list, test_list = [], [], []\n",
    "\n",
    "for user_id, group in ratings_filtered.groupby('UserID'):\n",
    "    user_train, user_temp = train_test_split(group, test_size=0.30, random_state=42)\n",
    "    user_val, user_test = train_test_split(user_temp, test_size=0.50, random_state=42)\n",
    "    train_list.append(user_train)\n",
    "    val_list.append(user_val)\n",
    "    test_list.append(user_test)\n",
    "\n",
    "train_data = pd.concat(train_list).reset_index(drop=True)\n",
    "val_data = pd.concat(val_list).reset_index(drop=True)\n",
    "test_data = pd.concat(test_list).reset_index(drop=True)\n",
    "\n",
    "# Extraer tensores (incluyendo g√©neros ahora s√≠)\n",
    "train_user = torch.tensor(train_data['userIndex'].values, dtype=torch.long)\n",
    "train_movie = torch.tensor(train_data['movieIndex'].values, dtype=torch.long)\n",
    "train_rating = torch.tensor(train_data[rating_col].values, dtype=torch.float32)\n",
    "train_genres = torch.tensor(train_data[genre_columns].values, dtype=torch.float32)\n",
    "\n",
    "val_user = torch.tensor(val_data['userIndex'].values, dtype=torch.long)\n",
    "val_movie = torch.tensor(val_data['movieIndex'].values, dtype=torch.long)\n",
    "val_rating = torch.tensor(val_data[rating_col].values, dtype=torch.float32)\n",
    "val_genres = torch.tensor(val_data[genre_columns].values, dtype=torch.float32)\n",
    "\n",
    "test_user = torch.tensor(test_data['userIndex'].values, dtype=torch.long)\n",
    "test_movie = torch.tensor(test_data['movieIndex'].values, dtype=torch.long)\n",
    "test_rating = torch.tensor(test_data[rating_col].values, dtype=torch.float32)\n",
    "test_genres = torch.tensor(test_data[genre_columns].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset personalizado ya lo definiste antes (con genre incluido)\n",
    "\n",
    "train_dataset = MovieLensDataset(train_user, train_movie, train_genres, train_rating)\n",
    "val_dataset = MovieLensDataset(val_user, val_movie, val_genres, val_rating)\n",
    "test_dataset = MovieLensDataset(test_user, test_movie, test_genres, test_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 512  # Puedes ajustarlo seg√∫n tu GPU\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, num_genres, embedding_dim_gmf=32, embedding_dim_mlp=32, dropout=0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embeddings GMF\n",
    "        self.user_embedding_gmf = nn.Embedding(num_users, embedding_dim_gmf)\n",
    "        self.movie_embedding_gmf = nn.Embedding(num_movies, embedding_dim_gmf)\n",
    "\n",
    "        # Embeddings MLP\n",
    "        self.user_embedding_mlp = nn.Embedding(num_users, embedding_dim_mlp)\n",
    "        self.movie_embedding_mlp = nn.Embedding(num_movies, embedding_dim_mlp)\n",
    "\n",
    "        # Mini-MLP para g√©neros\n",
    "        self.genre_layer = nn.Sequential(\n",
    "            nn.Linear(num_genres, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        # MLP principal\n",
    "        self.fc1 = nn.Linear(embedding_dim_mlp * 2 + 32, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Capa final (concatena GMF + MLP)\n",
    "        self.output = nn.Linear(embedding_dim_gmf + 64, 1)\n",
    "\n",
    "    def forward(self, user, movie, genre):\n",
    "        # GMF\n",
    "        user_gmf = self.user_embedding_gmf(user)\n",
    "        movie_gmf = self.movie_embedding_gmf(movie)\n",
    "        gmf_output = user_gmf * movie_gmf\n",
    "\n",
    "        # MLP\n",
    "        user_mlp = self.user_embedding_mlp(user)\n",
    "        movie_mlp = self.movie_embedding_mlp(movie)\n",
    "        genre_repr = self.genre_layer(genre)\n",
    "\n",
    "        mlp_input = torch.cat([user_mlp, movie_mlp, genre_repr], dim=1)\n",
    "        x = F.relu(self.bn1(self.fc1(mlp_input)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Final\n",
    "        final_input = torch.cat([gmf_output, x], dim=1)\n",
    "        out = self.output(final_input)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "model = NeuMF(\n",
    "    num_users=len(user_encoder.classes_),\n",
    "    num_movies=len(movie_encoder.classes_),\n",
    "    num_genres=len(genre_columns),\n",
    "    embedding_dim_gmf=32,\n",
    "    embedding_dim_mlp=32,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# P√©rdida\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizador\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Scheduler: reduce el LR si no mejora la validaci√≥n\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.0227 | Val Loss: 0.0309\n",
      "Epoch 2/30 | Train Loss: 0.0224 | Val Loss: 0.0310\n",
      "Epoch 3/30 | Train Loss: 0.0224 | Val Loss: 0.0311\n",
      "Epoch 4/30 | Train Loss: 0.0223 | Val Loss: 0.0311\n",
      "Epoch 5/30 | Train Loss: 0.0222 | Val Loss: 0.0312\n",
      "Epoch 6/30 | Train Loss: 0.0221 | Val Loss: 0.0312\n",
      "üîï Early stopping activado.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        users = batch['user'].to(device)\n",
    "        movies = batch['movie'].to(device)\n",
    "        genres = batch['genre'].to(device)\n",
    "        ratings = batch['rating'].to(device)\n",
    "\n",
    "        preds = model(users, movies, genres)\n",
    "        loss = criterion(preds, ratings)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * len(ratings)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # VALIDACI√ìN\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            users = batch['user'].to(device)\n",
    "            movies = batch['movie'].to(device)\n",
    "            genres = batch['genre'].to(device)\n",
    "            ratings = batch['rating'].to(device)\n",
    "\n",
    "            preds = model(users, movies, genres)\n",
    "            loss = criterion(preds, ratings)\n",
    "            val_loss += loss.item() * len(ratings)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # EARLY STOPPING\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stopping_counter = 0\n",
    "        #torch.save(model.state_dict(), \"best_model_with_genres.pth\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"üîï Early stopping activado.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√©tricas de Test:\n",
      "RMSE: 0.8811\n",
      "MAE : 0.6898\n",
      "R¬≤  : 0.3780\n",
      "Precision@10: 0.6470\n",
      "NDCG@10: 0.9299\n",
      "Tiempo total de evaluaci√≥n: 1.87 s\n",
      "‚úÖ M√©tricas exportadas a 'neumf_1m_metrics_with_genres.csv'.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# Medir tiempo\n",
    "start_time = time.time()\n",
    "\n",
    "# Cargar mejor modelo\n",
    "model.eval()\n",
    "\n",
    "# Evaluaci√≥n sobre el set de test\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        users = batch['user'].to(device)\n",
    "        movies = batch['movie'].to(device)\n",
    "        genres = batch['genre'].to(device)\n",
    "        ratings = batch['rating'].to(device)\n",
    "\n",
    "        preds = model(users, movies, genres)\n",
    "\n",
    "        # Desnormalizar si es necesario\n",
    "        preds = preds * 5\n",
    "        ratings = ratings * 5\n",
    "\n",
    "        y_true.extend(ratings.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Precision@10 y NDCG@10\n",
    "k = 10\n",
    "user_preds = defaultdict(list)\n",
    "user_truth = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        users = batch['user'].to(device)\n",
    "        movies = batch['movie'].to(device)\n",
    "        genres = batch['genre'].to(device)\n",
    "        ratings = batch['rating'].to(device)\n",
    "        preds = model(users, movies, genres)\n",
    "\n",
    "        preds = preds * 5\n",
    "        ratings = ratings * 5\n",
    "\n",
    "        for u, pred, true in zip(users.cpu().numpy(), preds.cpu().numpy(), ratings.cpu().numpy()):\n",
    "            user_preds[u].append(pred)\n",
    "            user_truth[u].append(true)\n",
    "\n",
    "precisions = []\n",
    "for u in user_preds:\n",
    "    preds_u = np.array(user_preds[u])\n",
    "    truths_u = np.array(user_truth[u])\n",
    "    top_k_indices = np.argsort(-preds_u)[:k]\n",
    "    relevant = (truths_u >= 4.0)\n",
    "    precisions.append(np.sum(relevant[top_k_indices]) / k)\n",
    "precision_at_k = np.mean(precisions)\n",
    "\n",
    "def ndcg_at_k(relevances, k):\n",
    "    relevances = np.asarray(relevances)[:k]\n",
    "    if relevances.size == 0:\n",
    "        return 0.0\n",
    "    dcg = np.sum((2 ** relevances - 1) / np.log2(np.arange(2, relevances.size + 2)))\n",
    "    idcg = np.sum((2 ** np.sort(relevances)[::-1] - 1) / np.log2(np.arange(2, relevances.size + 2)))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "ndcgs = []\n",
    "for u in user_preds:\n",
    "    preds_u = np.array(user_preds[u])\n",
    "    truths_u = np.array(user_truth[u])\n",
    "    relevances = (truths_u >= 4.0).astype(int)\n",
    "    top_k_indices = np.argsort(-preds_u)[:k]\n",
    "    ndcgs.append(ndcg_at_k(relevances[top_k_indices], k))\n",
    "ndcg_at_k_value = np.mean(ndcgs)\n",
    "\n",
    "# Tiempo total\n",
    "total_training_time = time.time() - start_time\n",
    "\n",
    "# Imprimir m√©tricas\n",
    "print(\"M√©tricas de Test:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE : {mae:.4f}\")\n",
    "print(f\"R¬≤  : {r2:.4f}\")\n",
    "print(f\"Precision@{k}: {precision_at_k:.4f}\")\n",
    "print(f\"NDCG@{k}: {ndcg_at_k_value:.4f}\")\n",
    "print(f\"Tiempo total de evaluaci√≥n: {total_training_time:.2f} s\")\n",
    "\n",
    "# Guardar m√©tricas\n",
    "metrics = {\n",
    "    \"Model\": \"NeuMF + Genres (1M)\",\n",
    "    \"Test RMSE\": rmse,\n",
    "    \"Test MAE\": mae,\n",
    "    \"Test R2\": r2,\n",
    "    \"Precision@10\": precision_at_k,\n",
    "    \"NDCG@10\": ndcg_at_k_value,\n",
    "    \"Eval Time (s)\": total_training_time\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "metrics_df.to_csv(\"neumf_1m_metrics_with_genres.csv\", index=False)\n",
    "print(\"‚úÖ M√©tricas exportadas a 'neumf_1m_metrics_with_genres.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
